{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"58034_PrelimPS_Piol.ipynb","provenance":[{"file_id":"1MbVxEjH2Fruc4p-q9L-yWXUsU8NGqvP4","timestamp":1631529976483},{"file_id":"https://github.com/dyjdlopez/fund-of-aiml/blob/main/activities/02%20-%20Linear%20Algebra%20Review/fund_aiml_02v1_2021.ipynb","timestamp":1631527913285}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fte_zsqVdp8R"},"source":["# Topic02a : Prelim Problem Set I"]},{"cell_type":"markdown","metadata":{"id":"JpcY5oJ5eFxA"},"source":["## Case 1 **{To be deleted}**\n","Represent the following representations into its vectorized form using LaTeX.\n","> **Problem 1.a. System of Linear Equations**\n","$$\n","\\left\\{\n","    \\begin{array}{cc}\n","        -y+z=\\frac{1}{32}\\\\ \n","        \\frac{1}{2}x -2y=0 \\\\\n","        -x + \\frac{3}{7}z=\\frac{4}{5}\n","    \\end{array}\n","\\right. $$\n","> **Problem 1.b. Linear Combination**\n","$$  \\cos{(\\theta)}\\hat{i} + \\sin{(\\theta)}\\hat{j} - \\csc{(2\\theta)}\\hat{k}$$\n","> **Problem 1.c. Scenario**\n",">\n",">A conference has 200 student attendees, 45 professionals, and has 15 members of the panel. There is a team of 40 people on the organizing committee. Represent the *percent* composition of each *attendee* type of the conference in matrix form.\n","\n","Express your answers in LaTeX in the answer area.\n"]},{"cell_type":"markdown","metadata":{"id":"vo_c4LChv_8w"},"source":["Problem 1.a System of Linear Equations\n","\n","$$ \\begin{bmatrix} z \\\\ y\\end{bmatrix} = \\begin{bmatrix} 0 \\\\ -\\frac{1}{32} \\end{bmatrix} + t\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $$ \n","\n","$$ \\begin{bmatrix} x \\\\ y\\end{bmatrix} = \\begin{bmatrix} 0 \\\\0 \\end{bmatrix} + t\\begin{bmatrix} 4 \\\\ 1 \\end{bmatrix} $$\n","\n","$$ \\begin{bmatrix} x \\\\ z\\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 7 \\end{bmatrix} + t\\begin{bmatrix} 0 \\\\ \\frac{28}{35} \\end{bmatrix}$$\n","\n","\n","Problem 1.b Linear Combination\n","\n","\n","$$ \\begin{bmatrix} \\cos{[\\theta]} \\\\ sin{[\\theta]} \\\\ -csc{[2\\theta]}  \\end{bmatrix} \\cdot \\begin{bmatrix} \\hat{i} \\\\ \\hat{j} \\\\ \\hat{k} \\end{bmatrix}$$\n","\n","\n","Problem 1.c Scenario\n","\n","$$  Students = (x) =  \\frac{200}{260} \\times 100  =  76.92\\% $$\n","\n","$$ Professionals = (y) =  \\frac{45}{260} \\times 100  =  17.31\\% $$\n","\n","$$ Panel = (z) =  \\frac{15}{260} \\times 100  =  5.77\\% $$\n","\n","\n","$$ 100 \\times \\begin{bmatrix} \\frac{10}{13} & \\frac{9}{52} & \\frac{1}{52} \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y\\\\ z \\end{bmatrix}  =  \\begin{bmatrix} 76.92\\% x & 17.31\\%y & 5.77\\%z \\end{bmatrix}$$\n"]},{"cell_type":"markdown","metadata":{"id":"yHRRd-2Hv_2z"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Uvb1MGs9QNVt"},"source":["# Case 2\n","> **Problem 2.a: Vector Magnitude**\n","\n",">The magnitude of a vector is usually computed as:\n","$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n","Whereas $v$ is any vector and $a_k$ are its elements wherein $k$ is the size of $v$.\n","Re-formulate $||v||$ as a function of an inner product. Further discuss this concept and provide your user-defined function.\n","\n","> **Problem 2.b: Angle Between Vectors**\n","\n","> Inner products can also be related to the Law of Cosines. The property suggests that:\n","$$u\\cdot v = ||u||\\cdot||v||\\cos(\\theta)$$\n","Whereas $u$ and $v$ are vectors that have the same sizes and $\\theta$ is the angle between $u$ and $v$.\n","\n","> Explain the behavior of the dot product when the two vectors are perpendicular and when they are parallel.\n"]},{"cell_type":"markdown","metadata":{"id":"gx4NTK6toiIK"},"source":["##Case 2\n","\n","####Problem 2.a: Vector Magnitude\n","\n","Usual Formula:\n","$$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$\n","\n","Function of a Inner product on a space of all continuous functions on the closed interval from a to b\n","\n","$$||v|| = \\sqrt{\\langle v|v \\rangle} = \\sqrt{\\int_{a}^{b} v^2(x) \\,dx} $$\n","\n","\n","\\\\\n","\\---------------------------------------------------------------------------------------------------------------------------------------------\\\n","For getting the magnitude/length/norm of a vector, the usual formula used is the $$||v|| = \\sqrt{a_0^2 + a_1^2 + ... +a_n^2}$$ \n","which $||v||$ value is also called the Euclendian norm or $l_2-norm$ based on the formula (using $v$ to represent any vector) :  $$||v|| = ||v||_p = (\\sum_{i=1}^n {|v_i|}^p)^{\\frac{1}{p}} $$\n","where $p = 2$. \\\\\n","\n","A norm in the Inner Product Space and continuous function space be represented as: \n","\n","$$ ||v|| = {\\langle v|v \\rangle}  = \\int_{a}^{b} v^2(x) \\,dx$$ \n","\n","and since the given is a Eucledian Norm, the usual formula reformuled as a function of a inner product would look like this \n","\n","$$||v|| = \\sqrt{\\langle v|v \\rangle} = \\sqrt{\\int_{a}^{b} v^2(x) \\,dx} $$ or \n","\n","\n","\n","\n","$$||v|| = \\sqrt{\\langle v|v \\rangle} = [\\int_{a}^{b} v^2(x) \\,dx]^\\frac{1}{2} $$\n","\n","\n","\n","\n","\n","\n","\n","\n","#### Problem 2.b\n","\n","The dot product of $||u||$ , $||v||$ , and  $\\cos(\\theta)$ with $\\theta = 90^\\circ$ or $270^\\circ$  would produce a result of $0$ since both non zero vectors $u$ and $v$ are perpendicular to each other and $\\cos{90} = {0}$. The dot product of a not zero vector to zero vector is equal to zero.\n","\n","$$u\\cdot v =||u||\\cdot||v||cos{90}$$ \n","$$u\\cdot v =(||u||\\cdot||v||)(0)$$\n","$$u\\cdot v = 0$$\n","\n","Therefore, Vector $u$ is **Orthological** or **Perpendicular** to Vector $v$.\n","\n","\n","\n","\\\\\n","The dot product of  $||u||$ , $||v||$ , and  $\\cos(\\theta)$ with $\\theta = 0^\\circ$ would produce an output that is the dot product of vectors $u$ and $v$ since the angle is $0$, therefore the both vectors are parallel to each other and $\\cos{0} = {1}$\n","\n","$$u\\cdot v =||u||\\cdot||v||cos{0}$$ \n","$$u\\cdot v =(||u||\\cdot||v||)(1)$$\n","$$u\\cdot v = ||u||\\cdot||v||$$\n","\n"]},{"cell_type":"code","metadata":{"id":"HE5VXs3vOKfX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_cH8JpkBj1xS"},"source":["# Case 3\n","For the final cases analysis we will be looking at series of equations building up a single feed-forward computation of a logistic regression. The case will not require you to learn fully what is logistic regression. \n","\n","$$X = \\begin{bmatrix} \n","— (x^{(1)})^T— \\\\ \n","— (x^{(2)})^T— \\\\\n","\\vdots \\\\\n","— (x^{(m)})^T— \\\\\n","\\end{bmatrix} \\text{, } \n","Y = \\begin{bmatrix} \n","y^{(1)} \\\\ \n","y^{(2)} \\\\\n","\\vdots \\\\\n","y^{(m)} \\\\\n","\\end{bmatrix} \\text{, and } \n","\\theta = \\begin{bmatrix} \n","\\theta^{(1)} \\\\ \n","\\theta^{(2)} \\\\\n","\\vdots \\\\\n","\\theta^{(m)} \\\\\n","\\end{bmatrix} $$\n","The dataset $X$ has $m$ entries with $n$ features while $Y$ is the vector containing the groud truths of a the entries of $X$, and $\\theta$ are the parameters or weights of the vectors. We first compute the vector product of the dataset and the parameters as:\n","$$ z = x^{(i)}\\theta^{(i)} = X\\cdot \\theta\\\\_{\\text{Eq. 3.1}}$$\n","We then solve for the hypothesis of the logistic regression alogrithm as:\n","\n","$$ h_\\theta(x) = g(z)\\\\_{\\text{Eq. 3.2}}$$\n","\n","Where $g$ is an acitvation function that maps the values of the hypothesis vector between a range of 0 and 1. We computed the activation as a sigmoid function:\n","$$g(z) = \\frac{1}{1+e^{-z}}\\\\_{\\text{Eq. 3.3}}$$\n","Finally we compute the loss of the logistic regression algorithm using $J$. Wheras $J(\\theta)$ is a function that computes the logistic loss of the hypothesis with respect to the ground truths $y$. it is then computed as:\n","$$J(\\theta) = \\frac{1}{m} \\sum^m_{i=0}=[-y^{(i)}\\log({h_{\\theta}(x^{(i)})})-(1-y^{(i)})\\log(1-h_{\\theta}(x^{(i)}))]\\\\_{\\text{Eq. 3.4}}$$"]},{"cell_type":"markdown","metadata":{"id":"MQ8jJV9-qyFy"},"source":["> **Problem 3.a: Matrix Equivalences**\n","\n","> In Eq. 1, $z$ can also be solved as $X \\cdot \\theta$ which is the vectorized form of $x^{(i)}\\theta^{(i)}$. However, it can also be expressed as $\\theta^T\\cdot X$. Prove the equality of $X \\cdot \\theta$ with $\\theta^T\\cdot X$ in this case.\n","\n","$h_\\theta = \\theta^T\\cdot X$\n","\n","> **Problem 3.b: Matrix Shapes**\n","\n","> Determine the shape of $h_\\theta$ if $X$ has a shape of $(300,5)$.\n","\n","> **Problem 3.c: Vectorization**\n","\n","> Express $J(\\theta)$ into its vectorized form.\n","\n","> **Problem 4.c: Computational Programming (Also Laboratory 2)**\n","\n","> Encode Equations 3.1 to 3.4 as the class `LRegression` wherein:\n","\n","> * `LRegression` should be instantiated with a dataset $X$, a ground truth vector $y$, and a parameter vector $\\theta$. Each parameter should have a data type of `numpy.array`.\n","> * It should further have `methods`reflecting to at least the four (4) aforementioned equations. Each should have a return value.\n"]}]}